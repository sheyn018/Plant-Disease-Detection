{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGE PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resizing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def resize_images(input_path, output_path, target_size=(256, 256), compression_quality=85):\n",
    "    # Open the image\n",
    "    image = Image.open(input_path)\n",
    "\n",
    "    # Resize the image\n",
    "    resized_image = image.resize(target_size)\n",
    "\n",
    "    # Convert the image to RGB before saving as JPEG\n",
    "    rgb_image = resized_image.convert('RGB')\n",
    "\n",
    "    # Save the resized image with compression\n",
    "    rgb_image.save(output_path, quality=compression_quality)\n",
    "\n",
    "# Dataset path\n",
    "ds_path = r\"dataset/images\"\n",
    "\n",
    "# Count the number of subfolders in the dataset path to determine the number of classes\n",
    "class_folders = [f for f in os.listdir(ds_path) if os.path.isdir(os.path.join(ds_path, f))]\n",
    "num_classes = len(class_folders)\n",
    "\n",
    "print(\"Number of Classes: \", num_classes)\n",
    "print(\"Classes: \", class_folders)\n",
    "\n",
    "for folder in class_folders:\n",
    "    disease_folder = os.path.join(ds_path, folder)\n",
    "\n",
    "    print('Processing images in folder: ', folder)\n",
    "\n",
    "    # Create a folder for the processed images if it doesn't exist\n",
    "    output_folder = os.path.join('dataset/other images', f\"{folder}_processed\")\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for image_name in os.listdir(disease_folder):\n",
    "        input_image_path = os.path.join(disease_folder, image_name)\n",
    "        output_image_path = os.path.join(output_folder, image_name)\n",
    "\n",
    "        # Call the function to resize the image to 256 x 256 pixels and compress the image\n",
    "        resize_images(input_image_path, output_image_path, target_size=(256, 256))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rembg import remove\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Function to remove background from an image\n",
    "def remove_background(input_path, output_path):\n",
    "    input_image = Image.open(input_path)\n",
    "    output_image = remove(input_image)\n",
    "    output_image = output_image.convert('RGB')\n",
    "    output_image.save(output_path)\n",
    "\n",
    "# Assuming class_folders and ds_path are defined elsewhere in your code\n",
    "for folder in class_folders:\n",
    "    disease_folder = os.path.join(ds_path, folder)\n",
    "\n",
    "    print('Processing images in folder: ', folder)\n",
    "\n",
    "    # Create a folder for the processed images if it doesn't exist\n",
    "    output_folder = os.path.join('dataset/other images', f\"{folder}_processed\")\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for image_name in os.listdir(disease_folder):\n",
    "        input_image_path = os.path.join(disease_folder, image_name)\n",
    "        output_image_path = os.path.join(output_folder, image_name)\n",
    "\n",
    "        # Call the function to remove the background from the image\n",
    "        remove_background(input_image_path, output_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W62QS_j2kS93"
   },
   "source": [
    "# EDI-FEATURES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ezJqQ5XxkXRX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.feature import graycomatrix, graycoprops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aHfhJgcPlvNq"
   },
   "outputs": [],
   "source": [
    "ds_path = r\"dataset/images\"\n",
    "diseases= os.listdir(ds_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aeEDqxeFmkLM",
    "outputId": "01828314-680a-4165-c486-9277280b7a97"
   },
   "outputs": [],
   "source": [
    "diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure\n",
    "from skimage.feature import hog\n",
    "from skimage.measure import regionprops\n",
    "from scipy import stats\n",
    "from skimage.measure import label\n",
    "\n",
    "# Set the dataset path\n",
    "ds_path = r\"dataset/images\"\n",
    "\n",
    "def features():\n",
    "    names = ['area', 'perimeter', 'physiological_length', 'physiological_width', 'aspect_ratio',\n",
    "             'mean_r', 'mean_g', 'mean_b', 'stddev_r', 'stddev_g', 'stddev_b',\n",
    "             'contrast', 'energy', 'homogeneity', 'correlation', 'dissimilarity',\n",
    "             'eccentricity', 'solidity', 'equiv_diameter', 'major_axis_length', 'minor_axis_length',\n",
    "             'skewness', 'kurtosis', 'hog_feature_1', 'hog_feature_2', 'hog_feature_3', 'types'\n",
    "            ]\n",
    "    df = pd.DataFrame(columns=names)\n",
    "\n",
    "    # Count the number of subfolders in the dataset path to determine the number of classes (labels)\n",
    "    class_folders = [f for f in os.listdir(ds_path) if os.path.isdir(os.path.join(ds_path, f))]\n",
    "    num_classes = len(class_folders)\n",
    "\n",
    "    print(\"Number of Classes: \", num_classes)\n",
    "    print(\"Classes: \", class_folders)\n",
    "\n",
    "    for folder in class_folders:\n",
    "        disease_folder = os.path.join(ds_path, folder)\n",
    "\n",
    "        print('Extracting features in folder: ', folder)\n",
    "        types = folder\n",
    "        index = 0\n",
    "        image_count = 0  # Counter for the number of images in the folder\n",
    "        \n",
    "        for image in os.listdir(disease_folder):\n",
    "            index = index + 1\n",
    "            image_count += 1  # Increment the counter for each image\n",
    "            imgpath = os.path.join(disease_folder, image)\n",
    "            main_img = cv2.imread(imgpath)\n",
    "\n",
    "            # Preprocessing\n",
    "            img = cv2.cvtColor(main_img, cv2.COLOR_BGR2RGB)\n",
    "            gs = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "            blur = cv2.GaussianBlur(gs, (25, 25), 0)\n",
    "            ret, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "            kernel = np.ones((50, 50), np.uint8)\n",
    "            closing = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "            # Shape features\n",
    "            contours, _ = cv2.findContours(closing, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            cnt = contours[0]\n",
    "            area = cv2.contourArea(cnt)\n",
    "            perimeter = cv2.arcLength(cnt, True)\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            aspect_ratio = float(w) / h\n",
    "\n",
    "            # Color features\n",
    "            red_channel = img[:, :, 0]\n",
    "            green_channel = img[:, :, 1]\n",
    "            blue_channel = img[:, :, 2]\n",
    "\n",
    "            red_mean = np.mean(red_channel)\n",
    "            green_mean = np.mean(green_channel)\n",
    "            blue_mean = np.mean(blue_channel)\n",
    "\n",
    "            # Std deviation\n",
    "            red_std = np.std(red_channel)\n",
    "            green_std = np.std(green_channel)\n",
    "            blue_std = np.std(blue_channel)\n",
    "\n",
    "            # Texture features using GLCM matrix\n",
    "            glcm = graycomatrix(gs,\n",
    "                                distances=[1],\n",
    "                                angles=[0],\n",
    "                                symmetric=True,\n",
    "                                normed=True)\n",
    "\n",
    "            properties = ['contrast', 'energy', 'homogeneity', 'correlation', 'dissimilarity']\n",
    "            contrast = graycoprops(glcm, properties[0])\n",
    "            energy = graycoprops(glcm, properties[1])\n",
    "            homogeneity = graycoprops(glcm, properties[2])\n",
    "            correlation = graycoprops(glcm, properties[3])\n",
    "            dissimilarity = graycoprops(glcm, properties[4])\n",
    "\n",
    "            # Statistical moments\n",
    "            skewness = stats.skew(gs.flatten())\n",
    "            kurtosis = stats.kurtosis(gs.flatten())\n",
    "\n",
    "            # Additional features\n",
    "            labeled_img = label(closing)\n",
    "            regions = regionprops(labeled_img)\n",
    "\n",
    "            eccentricity = regions[0].eccentricity\n",
    "            solidity = regions[0].solidity\n",
    "            equiv_diameter = regions[0].equivalent_diameter\n",
    "            major_axis_length = regions[0].major_axis_length\n",
    "            minor_axis_length = regions[0].minor_axis_length\n",
    "\n",
    "            # HOG features\n",
    "            hog_features = hog(gs, orientations=8, pixels_per_cell=(8, 8), cells_per_block=(1, 1), block_norm='L2-Hys')\n",
    "\n",
    "            vector = [area, perimeter, w, h, aspect_ratio,\n",
    "                      red_mean, green_mean, blue_mean, red_std, green_std, blue_std,\n",
    "                      contrast[0][0], energy[0][0], homogeneity[0][0], correlation[0][0], dissimilarity[0][0],\n",
    "                      eccentricity, solidity, equiv_diameter, major_axis_length, minor_axis_length,\n",
    "                      skewness, kurtosis, hog_features[0], hog_features[1], hog_features[2], types]\n",
    "\n",
    "            df_temp = pd.DataFrame([vector], columns=names)\n",
    "            df = pd.concat([df, df_temp], ignore_index=True)\n",
    "\n",
    "        print(f\"Number of images in folder '{folder}': {image_count}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-lFnHs23qIEm",
    "outputId": "2357cf1b-5b79-4cf6-8c79-5797b8f93668"
   },
   "outputs": [],
   "source": [
    "# Call the function to create the feature dataframe\n",
    "feature_df = features()\n",
    "\n",
    "# Save the resulting dataframe to a CSV file\n",
    "feature_df.to_csv(\"dataset/csv/image_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "LstkxK4PqyIT",
    "outputId": "0fb50158-f798-48a8-ebdd-55091489d77b"
   },
   "outputs": [],
   "source": [
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILev7gnvs0Js"
   },
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset/csv/image_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame with the features\n",
    "X = df.drop('types', axis=1)\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_explained_variance = explained_variance_ratio.cumsum()\n",
    "\n",
    "plt.plot(cumulative_explained_variance, marker='o')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w04RPlfUr_CR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8GeQkN7Js7JT"
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"dataset/csv/image_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Nuk3yoktC6A"
   },
   "outputs": [],
   "source": [
    "types = data[\"types\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I834En5CU_li",
    "outputId": "2fcd799f-6675-48d6-a265-ce7d7fe64441"
   },
   "outputs": [],
   "source": [
    "types_labels = types.unique()\n",
    "types_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('types', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "i86kptKJtDX4",
    "outputId": "157bbbaf-8f25-4d30-e81a-7429653ccabe"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "gzoEnjdztFV_",
    "outputId": "3b2f80c4-077e-4a7c-92e4-fc7c69ac38e8"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 14)\n",
    "pca.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6arhkPO72oMY",
    "outputId": "1257ba22-75e2-4c74-9ced-ca1da37694a5"
   },
   "outputs": [],
   "source": [
    "# Access the loadings of the first three principal components\n",
    "loadings = pca.components_[:14]\n",
    "\n",
    "# Map the loadings to the original feature names\n",
    "original_feature_names = data.columns\n",
    "component_loadings = pd.DataFrame(loadings, columns=original_feature_names)\n",
    "\n",
    "# Display the loadings for the first three components\n",
    "print(component_loadings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UaHR4IkytIvE"
   },
   "outputs": [],
   "source": [
    "data2=pca.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0IHMWBmYtJ-h",
    "outputId": "a1eb4ea5-2873-4bbd-f5aa-023dd3a1da5e"
   },
   "outputs": [],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UHS50kqEtLbe"
   },
   "outputs": [],
   "source": [
    "data2=pd.DataFrame(data2)\n",
    "data2 = data2.join(types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "g5P9nKYutNHi",
    "outputId": "288bd27e-f408-49a0-8007-454a22831014"
   },
   "outputs": [],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-4GFnpsJtOwJ"
   },
   "outputs": [],
   "source": [
    "data2.index=data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "rurrHOUQtQCj",
    "outputId": "30361353-6b48-40f7-ffc2-77c8445c3ec6"
   },
   "outputs": [],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0xnslH7AtRL4",
    "outputId": "9cdeb683-7db3-4052-b464-57113ba53ab0"
   },
   "outputs": [],
   "source": [
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mKujzSEOtSvE",
    "outputId": "a3392cbf-8cfb-48ad-ec50-5e55e4ad6229"
   },
   "outputs": [],
   "source": [
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HuahHHi5tU3c"
   },
   "outputs": [],
   "source": [
    "data2.to_csv(\"dataset/csv/pca.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# Save the PCA model to a file\n",
    "joblib.dump(pca, 'models/pca/Apple_pca_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hbks6Stftjp8"
   },
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LIdipuJvtgAJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QVrIn9PTtohA"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"dataset/csv/pca.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "Qgi-7hj2tp2X",
    "outputId": "fbf8e5f4-dc79-483f-a499-7dfc2936d79d"
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8A_yZiJUyGUS"
   },
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sdT4CZjSsX3R",
    "outputId": "fb454d4d-bbf6-42cb-de9f-2820847a0033"
   },
   "outputs": [],
   "source": [
    "# Extract the features (X) and labels (y)\n",
    "X = data.iloc[:, :-1]  # Select all columns except the last one as features\n",
    "y = data['types']  # Select the 'types' column as the target variable\n",
    "\n",
    "# Check the shape of X and y to ensure they are correct\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "WXrMdMzFtINe",
    "outputId": "07ecae1f-6240-4585-a0ea-af651dabe814"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# Extract the features (X) and labels (y)\n",
    "X = data.iloc[:, :-1]  # Select all columns except the last one as features\n",
    "y = data['types']  # Select the 'types' column as the target variable\n",
    "\n",
    "# Check the class distribution before applying SMOTE\n",
    "label_counts_before = y.value_counts()\n",
    "print(\"Class distribution before SMOTE:\")\n",
    "print(label_counts_before)\n",
    "\n",
    "# Create a bar chart to visualize the class distribution before SMOTE\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(label_counts_before.index, label_counts_before.values)\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Class Distribution Before SMOTE')\n",
    "plt.show()\n",
    "\n",
    "# Create an instance of the SMOTE class\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "# Apply SMOTE to balance the dataset\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Check the class distribution after applying SMOTE\n",
    "label_counts_after = Counter(y_resampled)\n",
    "print(\"Class distribution after SMOTE:\")\n",
    "print(label_counts_after)\n",
    "\n",
    "# Create a bar chart to visualize the class distribution after SMOTE\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(label_counts_after.keys(), label_counts_after.values())\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Class Distribution After SMOTE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7V_j2s9avPWb"
   },
   "outputs": [],
   "source": [
    "# Overwrite DataFrame with the resampled data\n",
    "data = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "data['types'] = y_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxYzfU99yKjc"
   },
   "source": [
    "### Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qZJPoKoOtrDo"
   },
   "outputs": [],
   "source": [
    "x=data.iloc[:,0:14].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7fp9dT6Htuhi",
    "outputId": "a8f702d3-e18d-42d4-ac04-33f44a371c11"
   },
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "65iWAYdgtvr5",
    "outputId": "886720b7-9ade-47f5-8d8a-4dad9e9bffdd"
   },
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QEZwVpOdtxAu"
   },
   "outputs": [],
   "source": [
    "y=data.iloc[:,14].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SVS4I-mPtyO7",
    "outputId": "860c2dae-29e2-42d0-fc42-ae7586de0441"
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eDlnB-lltzmX"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "data2=StandardScaler()\n",
    "x=data2.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model to a file\n",
    "joblib.dump(data2, 'models/scalers/Apple_scaler_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MMgVI393t0um",
    "outputId": "20b2fd15-4e9e-4c22-b98e-d540afbd4402"
   },
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nQTQRp4Ut2ze"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6k5ppePD_hjr"
   },
   "source": [
    "### Default Parameters Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tmbb2gg3t4c6"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Assuming x_train is your feature matrix and y_train is your target variable as a NumPy array\n",
    "svm = SVC()\n",
    "\n",
    "# Train the SVM model\n",
    "strain = svm.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "gJwa7r85t8aW",
    "outputId": "1fbed260-5103-4719-ac59-0205499ecb22"
   },
   "outputs": [],
   "source": [
    "strain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model to a file\n",
    "joblib.dump(strain, 'models/classifiers/Apple_classifier_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8zlMICAkyPss"
   },
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EQD5xxINt92B",
    "outputId": "e0e25db0-9a02-4fbb-9085-d556f0dff6ac"
   },
   "outputs": [],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AO88OgAdt_Ox"
   },
   "outputs": [],
   "source": [
    "y_pred=strain.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XklSeMzduAqr",
    "outputId": "a2ef23a4-aa53-4ef4-9223-2bd46366b7e1"
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j885OsvouB8R",
    "outputId": "3b78cde5-2b87-4939-eac3-51a21f3c2681"
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of Training Data:\", len(y_train))\n",
    "print(\"Number of Testing Data:\", len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "887u3OPDuDPq",
    "outputId": "8896949b-55b4-422a-e40c-bc7f5558adda"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rz7_6ObeuFGW",
    "outputId": "34ccfc1a-691f-41e8-9afd-470734e2256c"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_img = cv2.imread('dataset/images/Cedar apple rust/0cd24b0c-0a9d-483f-8734-5c08988e029f___FREC_C.Rust 3762.jpg')\n",
    "\n",
    "names = ['area', 'perimeter', 'physiological_length', 'physiological_width', 'aspect_ratio',\n",
    "             'mean_r', 'mean_g', 'mean_b', 'stddev_r', 'stddev_g', 'stddev_b',\n",
    "             'contrast', 'energy', 'homogeneity', 'correlation', 'dissimilarity',\n",
    "             'eccentricity', 'solidity', 'equiv_diameter', 'major_axis_length', 'minor_axis_length',\n",
    "             'skewness', 'kurtosis', 'hog_feature_1', 'hog_feature_2', 'hog_feature_3'\n",
    "            ]\n",
    "df = pd.DataFrame(columns=names)\n",
    "\n",
    "# Preprocessing\n",
    "img = cv2.cvtColor(main_img, cv2.COLOR_BGR2RGB)\n",
    "gs = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "blur = cv2.GaussianBlur(gs, (25, 25), 0)\n",
    "ret, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "kernel = np.ones((50, 50), np.uint8)\n",
    "closing = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "# Shape features\n",
    "contours, _ = cv2.findContours(closing, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnt = contours[0]\n",
    "area = cv2.contourArea(cnt)\n",
    "perimeter = cv2.arcLength(cnt, True)\n",
    "x, y, w, h = cv2.boundingRect(cnt)\n",
    "aspect_ratio = float(w) / h\n",
    "\n",
    "# Color features\n",
    "red_channel = img[:, :, 0]\n",
    "green_channel = img[:, :, 1]\n",
    "blue_channel = img[:, :, 2]\n",
    "\n",
    "red_mean = np.mean(red_channel)\n",
    "green_mean = np.mean(green_channel)\n",
    "blue_mean = np.mean(blue_channel)\n",
    "\n",
    "# Std deviation\n",
    "red_std = np.std(red_channel)\n",
    "green_std = np.std(green_channel)\n",
    "blue_std = np.std(blue_channel)\n",
    "\n",
    "# Texture features using GLCM matrix\n",
    "glcm = graycomatrix(gs,\n",
    "                distances=[1],\n",
    "                angles=[0],\n",
    "                symmetric=True,\n",
    "                normed=True)\n",
    "\n",
    "properties = ['contrast', 'energy', 'homogeneity', 'correlation', 'dissimilarity']\n",
    "contrast = graycoprops(glcm, properties[0])\n",
    "energy = graycoprops(glcm, properties[1])\n",
    "homogeneity = graycoprops(glcm, properties[2])\n",
    "correlation = graycoprops(glcm, properties[3])\n",
    "dissimilarity = graycoprops(glcm, properties[4])\n",
    "\n",
    "# Statistical moments\n",
    "skewness = stats.skew(gs.flatten())\n",
    "kurtosis = stats.kurtosis(gs.flatten())\n",
    "\n",
    "# Additional features\n",
    "labeled_img = label(closing)\n",
    "regions = regionprops(labeled_img)\n",
    "\n",
    "eccentricity = regions[0].eccentricity\n",
    "solidity = regions[0].solidity\n",
    "equiv_diameter = regions[0].equivalent_diameter\n",
    "major_axis_length = regions[0].major_axis_length\n",
    "minor_axis_length = regions[0].minor_axis_length\n",
    "\n",
    "# HOG features\n",
    "hog_features = hog(gs, orientations=8, pixels_per_cell=(8, 8), cells_per_block=(1, 1), block_norm='L2-Hys')\n",
    "\n",
    "vector = [area, perimeter, w, h, aspect_ratio,\n",
    "        red_mean, green_mean, blue_mean, red_std, green_std, blue_std,\n",
    "        contrast[0][0], energy[0][0], homogeneity[0][0], correlation[0][0], dissimilarity[0][0],\n",
    "        eccentricity, solidity, equiv_diameter, major_axis_length, minor_axis_length,\n",
    "        skewness, kurtosis, hog_features[0], hog_features[1], hog_features[2]]\n",
    "\n",
    "df_temp = pd.DataFrame([vector], columns=names)\n",
    "df = pd.concat([df, df_temp], ignore_index=True)\n",
    "\n",
    "pca_model = joblib.load('models/pca/Apple_pca_model.pkl')\n",
    "pca = pca_model.transform(df)\n",
    "\n",
    "scaler_model = joblib.load('models/scalers/Apple_scaler_model.pkl')\n",
    "scaled = scaler_model.transform(pca)\n",
    "\n",
    "classifier_model = joblib.load('models/classifiers/Apple_classifier_model.pkl')\n",
    "results = classifier_model.predict(scaled)\n",
    "\n",
    "print('FEATURES', df)\n",
    "print('PCA', pca)\n",
    "print('SCALED', scaled)\n",
    "print('RESULTS', results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7W-Z2du6Isj"
   },
   "source": [
    "### Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 872
    },
    "id": "Mi36sen15YST",
    "outputId": "7c6cb7e0-e508-4e29-f00a-9d2f1fc852b1"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'y_test' contains the true labels and 'y_pred' contains the predicted labels\n",
    "conf_mat = confusion_matrix(y_test, y_pred, labels=data['types'].unique())\n",
    "\n",
    "# Create the heatmap\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d',\n",
    "            xticklabels=data['types'].unique(),\n",
    "            yticklabels=data['types'].unique())\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title(\"Confusion Matrix - Linear SVC\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J8xrBjBr5c65",
    "outputId": "d44d24c2-c2b7-4dd4-b2bf-3642ba08236a"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming you have true labels (y_true) and predicted labels (y_pred)\n",
    "y_true = y_test\n",
    "y_pred = y_pred\n",
    "\n",
    "data=pd.read_csv(\"dataset/csv/image_features.csv\")\n",
    "types = data[\"types\"]\n",
    "types_labels = types.unique()\n",
    "\n",
    "# Compute precision, recall, and F1-score for each class\n",
    "classes =  types_labels\n",
    "\n",
    "precision = precision_score(y_true, y_pred, labels=classes, average=None, zero_division=0)\n",
    "recall = recall_score(y_true, y_pred, labels=classes, average=None, zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, labels=classes, average=None, zero_division=0)\n",
    "\n",
    "# Display the results for each class\n",
    "for class_label, p, r, f in zip(classes, precision, recall, f1):\n",
    "    print(f\"Class {class_label} - Precision: {p} \\n\\t\\t  Recall: {r} \\n\\t\\t  F1-Score: {f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x97tmcSQ_dZ9"
   },
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "koXHWanJgnRK",
    "outputId": "6720261e-a020-49ee-a4b6-3321eec98ecc"
   },
   "outputs": [],
   "source": [
    "import threading\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],  # Kernel types\n",
    "    'gamma': ['scale', 'auto'] + [0.001, 0.01, 0.1, 1, 10]  # Kernel coefficient (only for 'rbf', 'poly', 'sigmoid')\n",
    "}\n",
    "\n",
    "# Create an SVM model\n",
    "svm = SVC()\n",
    "\n",
    "# Create a GridSearchCV object with the SVM model and parameter grid\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Initialize a variable to keep track of the number of combinations\n",
    "total_combinations = len(param_grid['C']) * len(param_grid['kernel']) * len(param_grid['gamma'])\n",
    "combination_count = 0\n",
    "\n",
    "# Create an empty list to store the results\n",
    "results = []\n",
    "\n",
    "# Lock for thread synchronization\n",
    "results_lock = threading.Lock()\n",
    "\n",
    "# Function to train the SVM model with a timeout\n",
    "def train_svm_with_timeout(C, kernel, gamma, result_flag):\n",
    "    try:\n",
    "        svm = SVC(C=C, kernel=kernel, gamma=gamma)\n",
    "        svm.fit(x_train, y_train)\n",
    "        y_pred = svm.predict(x_test)  # Predict on the test data\n",
    "        accuracy = (y_pred == y_test).mean()  # Calculate accuracy\n",
    "        with results_lock:\n",
    "            results.append([C, kernel, gamma, accuracy])\n",
    "        result_flag[0] = True\n",
    "    except Exception as e:\n",
    "        result_flag[0] = False\n",
    "\n",
    "# Fit the grid search to your training data\n",
    "for C in param_grid['C']:\n",
    "    for kernel in param_grid['kernel']:\n",
    "        for gamma in param_grid['gamma']:\n",
    "            combination_count += 1\n",
    "            print(f\"Combination {combination_count}/{total_combinations}: C={C}, kernel={kernel}, gamma={gamma}\")\n",
    "\n",
    "            result_flag = [False]\n",
    "\n",
    "            t = threading.Thread(target=train_svm_with_timeout, args=(C, kernel, gamma, result_flag))\n",
    "            t.start()\n",
    "            t.join(timeout=300)  # Adjust the timeout value as needed\n",
    "\n",
    "            if result_flag[0]:\n",
    "                print(\"Accuracy on test data: \", results[-1][-1])\n",
    "            else:\n",
    "                print(\"Training took too long or encountered an error. Skipping to the next combination.\")\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "result_df = pd.DataFrame(results, columns=[\"C\", \"Kernel\", \"Gamma\", \"Accuracy\"])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_csv = r\"dataset/csv/grid_search_results.csv\"\n",
    "result_df.to_csv(output_csv, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2GDDPFhXbe1"
   },
   "source": [
    "### Grid Search Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c9oUYBQqWuxJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "grid_df=pd.read_csv(\"dataset/csv/grid_search_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(grid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "O-_moD9EBSl4",
    "outputId": "d75a87ef-6407-48d6-eae1-abc2e99d3e18"
   },
   "outputs": [],
   "source": [
    "grid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-poYVx5PGsOv",
    "outputId": "bb3545f0-cac1-4e5e-ce6c-82f5566f1e36"
   },
   "outputs": [],
   "source": [
    "# Find the index of the row with the highest accuracy\n",
    "max_accuracy_index = grid_df['Accuracy'].idxmax()\n",
    "\n",
    "# Get the row with the highest accuracy\n",
    "row_with_highest_accuracy = grid_df.loc[max_accuracy_index]\n",
    "\n",
    "print(row_with_highest_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GvR5JjIWHVAA"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Specify the parameters\n",
    "C = float(row_with_highest_accuracy.C)\n",
    "kernel = row_with_highest_accuracy.Kernel\n",
    "gamma_value = row_with_highest_accuracy.Gamma\n",
    "\n",
    "# Check if gamma is a string and not 'auto' or 'scale'\n",
    "if isinstance(gamma_value, str):\n",
    "    try:\n",
    "        gamma = float(gamma_value)  # Try to convert to float\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Invalid gamma value\")\n",
    "else:\n",
    "    gamma = gamma_value  # It's either 'auto', 'scale', or a valid string\n",
    "\n",
    "# Create an SVC with the specified parameters\n",
    "svm = SVC(C=C, kernel=kernel, gamma=gamma)\n",
    "\n",
    "# Train the model on your training data\n",
    "train_grid = svm.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "Kv5dXdpFHwKZ",
    "outputId": "2053eec0-fefd-4e22-f6e9-6551df1c577e"
   },
   "outputs": [],
   "source": [
    "train_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model to a file\n",
    "joblib.dump(train_grid, 'models/classifiers/Apple_classifier_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6W9dE5PDH7dy"
   },
   "outputs": [],
   "source": [
    "y_pred=train_grid.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mufW_xTlH82J",
    "outputId": "087f12b3-5f7c-440f-9aa1-f09a234c328c"
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L9cHncURIAob",
    "outputId": "ee4db70d-dde7-4eda-b8ed-266fdfdef23f"
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ZZvrYbEIB4d",
    "outputId": "377f879b-d690-49ad-d81a-4e8b3a9680b6"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4iEOo5dXvx-"
   },
   "source": [
    "### Grid Search Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 872
    },
    "id": "KsR-naNCXJd1",
    "outputId": "5d0f9fca-62d2-4db3-f2f6-8d90213da193"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'y_test' contains the true labels and 'y_pred' contains the predicted labels\n",
    "conf_mat = confusion_matrix(y_test, y_pred, labels=data['types'].unique())\n",
    "\n",
    "# Create the heatmap\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d',\n",
    "            xticklabels=data['types'].unique(),\n",
    "            yticklabels=data['types'].unique())\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title(\"Confusion Matrix - Linear SVC\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MAcFnPHGXu1E",
    "outputId": "48396ef1-fa30-4d15-bfe2-ccbbd18e42b0"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming you have true labels (y_true) and predicted labels (y_pred)\n",
    "y_true = y_test\n",
    "y_pred = y_pred\n",
    "\n",
    "data=pd.read_csv(\"dataset/csv/image_features.csv\")\n",
    "types = data[\"types\"]\n",
    "types_labels = types.unique()\n",
    "\n",
    "# Compute precision, recall, and F1-score for each class\n",
    "classes = types_labels\n",
    "\n",
    "precision = precision_score(y_true, y_pred, labels=classes, average=None, zero_division=0)\n",
    "recall = recall_score(y_true, y_pred, labels=classes, average=None, zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, labels=classes, average=None, zero_division=0)\n",
    "\n",
    "# Display the results for each class\n",
    "for class_label, p, r, f in zip(classes, precision, recall, f1):\n",
    "    print(f\"Class {class_label} - Precision: {p} \\n\\t\\t  Recall: {r} \\n\\t\\t  F1-Score: {f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s4UKeglBX_1X"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
